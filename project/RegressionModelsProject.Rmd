---
title: "Regression Models Project"
author: "S. Phillips"
date: "November 15, 2015"
output: pdf_document
---

##Executive Summary
Motor Trends magazine has asked me to solve which features of an automobile affect fuel efficiency.  In particular, they are interested in comparing miles per gallon of automatic vs manual transmissions.  This document will walk the reader through the analysis and its conclusion given in the summary.

```{r echo=FALSE}
library(ggplot2) #We'll need ggplot for graphs
library(knitr)
library(reshape2)
data(mtcars) #and the Motor Trends data set
```

##Exploratory Analysis of the Data and Their Corellations

Motor Trend's database lists 32 automobile models with 11 variables that could affect fuel efficiency.  To bring the characteristics of this data to light, the top rows are given below.

```{r echo=FALSE}
head(mtcars)
```

To gain a better understanding of the variables, we'll look at the correlation of each one independently against  __(mpg)__ and observe where  __(am)__ ranks among them.  These results predict a positive correlation that manual transmissions tend to deliver better overall gas mileage.  However, __am__ is less correlated than other variables. Also, the _qqnorm_ plots given in the Appendix show that many of our variables are subject to outliers - especially __(wt)__*.

_See Appendix: Selecting Predictors (QQNorm Plots)_

```{r echo=FALSE}
cor <- data.frame(sort(cor(mtcars)[1,]))
cor[1:11,2] <- c("Weight (lb/1000)","Number of cylinders", "Displacement (cu.in.)", "Gross horsepower", "Number of carburetors", "1/4 mile time", "Number of forward gears", "Transmission (0 = automatic, 1 = manual)", "Engine Type 0=V(as in V8) or 1=S(as in straight)","Rear axle ratio", "Miles/(US) gallon")

cor <- cor[c(2,1)]
names(cor) <- c("Description", "Correlation")
kable(cor)

```

##Evaluate Predicters for Model Selection

The notes below gather what we know about the correlations combined with domain knowledge gleaned from researching the data.

* Although __wt__ has significant outliers, the manufacturer data confirms accuracy so we accept it as a predictor candidate. *

* We'll exclude __cyl, disp and carb__ because they are likely predictors of __hp__.  Logically, __hp__ could be a predictor of __wt__ or high-performance. 

* The data in __qsec__ seems a good variable for predicting high-performance that has to be reconciled against __wt__.  Although __qsec__ is near the median of correlations, it is very locigal as a predictor.

*_See Appendix: Selecting Predicters (QQNorm Plots)_

The research up to this point indicates __am, wt, drat & qsec__ as the starting predictor list.  However, we will see changes our in our final selections based upon _Adjusted R Squared_ and _P Value_ results from exhaustive model permutations.

##Model Selection Strategy

From exhaustive testing of Multi-variable Regression Models, we found 3 finalists for best fit. We will eliminate one of them based upon results from _Adjusted R Squared_ and _P Values._  Last, we will use a plot of _Residuals_ to pick a best fit from our two finalists.

```{r echo=FALSE}

fit3 <- lm(mpg ~ wt + qsec + as.factor(am), data=mtcars) 
fit4 <- lm(mpg ~ hp + qsec + as.factor(am) * wt, data=mtcars) 
fit5 <- lm(mpg ~ wt + qsec + as.factor(am) * hp, data=mtcars) 

```

* FIT CANDIDATE 1: __mpg ~ wt + qsec + as.factor(am)__ Adj R Squared=`r summary(fit3)$adj`.  The p-values for this predictor all clearly reject the null hypothesis. However, the coefficients from the other two candidates were far stronger.  *

* FIT CANDIDATE 2: __mpg ~ hp + qsec + as.factor(am) * wt__  Adj R Squared=`r summary(fit4)$adj`. Highest R2 of all three models, but p values are weaker. __Wt__, in particular, indicates the alternative hypothesis. *

* FIT CANDIDATE 3: __mpg ~ wt + qsec + as.factor(am) * hp__ Adj R Squared=`r summary(fit5)$adj`. High R2, p-values reject Ho except for the hp confounder _hp_ which suggests Ha. *

*_See Appendix: Coefficients_

##Evaluate __Residuals__ to Select Best Fit

The _Residuals vs Fitted_ plot in the appendix indicate that FIT CANDIDATE 2's fit line stays closer to the mean and  the residuals are tighter than FIT CANDIDATE 3.  Also, the _Normal Q-Q_ plot shows that FIT CANDIDATE 2's residuals are closest to a normal distribution. 

*_See Appendix: Residuals for the Two Finalists_

#Conclusion

1. The best fit for predicting __mpg__ is FIT CANDIDATE 2: __lm(mpg ~ wt + qsec + as.factor(am) * wt)__
2. The 14 mpg in added fuel economy for FIT CANDIDATE 2 cant be trusted because of 3.....
3. All models with reasonably good coefficients predict that manual transmissions deliver better fuel economy than automatics. However, the mpg estimate is highly variable, and therefore, difficult to predict considering many results showing good fit such as High R-Squared, Residuals with Normal Distributions and P-values negating a null hypothesis. Ultimately, an array of statistically valid results with a wide range of estimated outcomes can't be trusted.

\pagebreak 

#Appendix

## Selecting Predictors (QQNorm Plots)

Use QQNorm plots to look at each variable to evaluate weights,leverage and distribution - perferring normal distributions and being mindful of outliers.

```{r echo=FALSE}
par(mfrow=c(3,4))
for(i in 1:11) 
{
 qqnorm(mtcars[,i], xlab=names(mtcars[i]), ylab="", main="")
}
```
Output from _Leaps_ regsubsets command.  Darkest columns are indicated as being predictors for __mpg__.

```{r echo=FALSE}

# library(leaps)
# leaps <- regsubsets(mpg ~ cyl+disp+hp+drat+wt+qsec+vs+am+gear+carb, data=mtcars,nbest=5)
# par(mar=c(1,1,1,1))
# plot(leaps, scale="adjr2")

```

## Coefficients

## Candidate 1

```{r echo=FALSE}
summary(fit3)$coef

```

## Candidate 2

```{r echo=FALSE}
summary(fit4)$coef

```

## Candidate 3

```{r echo=FALSE}

summary(fit5)$coef

```

##Residuals for the Two Finalists


##Candidate 2

```{r echo=FALSE}

layout(matrix(c(1,2,3,4),2,2))
plot(fit4)

```

##Candidate 3

```{r echo=FALSE}

layout(matrix(c(1,2,3,4),2,2))
plot(fit5)

```

```{r echo=FALSE}

# require(gridExtra)
# 
# 
# plot1 <- ggplot(mtcars, aes(y=mpg, x=factor(am, labels = c("automatic", "manual")), fill=factor(am))) +
#         geom_boxplot(colour="black", size=1) +
#         xlab("Transmission") + ylab("MPG")
# 
# plot2 <- ggplot(mtcars, aes(y=mpg, x=factor(vs, labels = c("V", "S")), fill=factor(vs))) +
#         geom_boxplot(colour="black", size=1) +
#         xlab("Engine Type") + ylab("MPG")
# 
# grid.arrange(plot1, plot2, ncol=2)

# library(corrgram)
# corrgram(mtcars, order=TRUE, lower.panel=panel.shade,
#   upper.panel=panel.pie, text.panel=panel.txt,
#   main="Car Milage Data in PC2/PC1 Order")
```

```{r echo=FALSE}

# summary(fit3)$coef
# summary(fit4)$coef
# 
# res3 <- resid(fit3)
# res4 <- resid(fit4)

```




